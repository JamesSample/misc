{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief notes inspired by my [Cross-Validated post](http://stats.stackexchange.com/questions/218667/simple-linear-regression-p-values-and-the-aic).\n",
    "\n",
    "When specifying regression models (e.g. in `statsmodels`), a shorthand syntax is used to represent the model. The syntax is as follows:\n",
    "\n",
    "### 1. A single explanatory variable\n",
    "\n",
    "`y ~ x` specifies the model $y = \\beta_0 + \\beta_1 x$\n",
    "\n",
    "This fits a single straight line and estimates the slope and intercept.\n",
    "\n",
    "### 2. Multiple explanatory variables but not interactions\n",
    "\n",
    "`y ~ x + z` specifies a model with two explanatory variables ($x$ and $z$): $y = \\beta_0 + \\beta_1 x + \\beta_2 z$. If z is a binary indicator variable (i.e. a categorical variable with two possible values) this essentially fits two separate lines. The estimate for $\\beta_2$ gives an indication of the effect of the category (i.e. how much the line shifts up or down between e.g. Norway and Germany), while $\\beta_1$ reflects the influence of $x$, having accounted for the category. In other words, you end up with two lines but the same slope.\n",
    "\n",
    "### 3. Multiple explanatory variables with interactions\n",
    "\n",
    "`y ~ x * z` specifies a model with two explanatory variables plus interactions: $y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x z$. If $z$ is binary (categorical), this corresponds to two lines with different slopes and intercepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
